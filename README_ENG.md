# [Switch to russian version](https://github.com/turing228/map-get-fresh-top-k/blob/master/README.md)

# Map With Getting Fresh Top K Keys library

<p align="center">
    <a href="https://github.com/turing228/map-get-fresh-top-k/blob/master/LICENSE">
        <img src="https://img.shields.io/github/license/turing228/map-get-fresh-top-k" title="Map-Get-Fresh-Top-K is released under the GNU GPL license." />
    </a>
    <a href="https://github.com/turing228/map-get-fresh-top-k/graphs/contributors">
        <img src="https://img.shields.io/github/contributors/turing228/map-get-fresh-top-k?color=orange" title="Contributors"/>
    </a>
    <img src="https://img.shields.io/github/repo-size/turing228/map-get-fresh-top-k" title="Repository size"/>
    <img src="https://img.shields.io/badge/build-passing-brightgreen" title="Build passing"/>
    <a href="https://github.com/turing228/map-get-fresh-top-k/stargazers">
        <img src="https://img.shields.io/github/stars/turing228/map-get-fresh-top-k?style=social" title="Stars"/>
    </a>
</p>

What are the most popular search requests at the last minute? How to analyze billions of requests per nanosecond and get top of the last minute? Just use this map! The solution is based on hard probabilistic mathematics — on the frequency estimation algorithm. I have analyzed different algorithms, implemented the best one, and tested it — now it is time to integrate it into your project!

## Contents:
- [🚀 Quickstart](#-quickstart)
- [☠️ Project Structure](#-project-structure)
- [🚄 Task In A Nutshell](#-task-in-a-nutshell)
- [💘 Solution](#-solution)
- [👪 Contributors](#-contributors)
- [📄 License](#-license)

## 🚀 Quickstart

To build library run from project directory: 

    ./make_lib.sh

To run tests run this from project directory (tests take ~15 minutes, Google Tests are using):

    #linux/macos
    ./run_tests.sh
    
    #windows cmd
    1. Run cmake-gui.exe
    2. Set sourse code place *project_directory* (without spaces!)
    3. Create and choose build_dir directory in the root of *project_directory* (without spaces!)
    3. Click "configure" and generate MinGW MakeFile
    cd build_dir
    cmake ..
    make all
    cd google_tests
    Google_Tests_run.exe

## ☠️ Project Structure

| Name | Description |
| --- | --- |
| main.cpp | Hello World! just check workability of MapGetFreshTopK |
| map_get_fresh_top_k_lib | Directory with files of realization of classes |
| map_get_fresh_top_k_lib/map_with_get_very_frequent.h | Class `MapGetFreshTopK` |
| map_get_fresh_top_k_lib/frequency_estimation_analyzer.h | Class `FrequencyEstimationAnalyzer`, which implements `MapGetFreshTopK` analyzer |
| google_tests | Directory with test files |
| google_tests/tests.cpp | Google tests |
| google_tests/accurate_frequency_analyzer.cpp | Class `AccurateFrequencyAnalyzer`, which implements naive exact analyzer for receiving top by number of requests keys (it uses for testing of `MapGetFreshTopK`) |
| google_tests/utility_functions.cpp | A lot of additional functions for Google tests |

Comments follow all files, classes, public methods, and important functions. [Google C++ Style Guide](https://google.github.io/styleguide/cppguide.html) is used.

## 🚄 Task In A Nutshell

1. Here is a stream of data (requests with keys)
1. We should answer on a request "give the list of keys, who met in at least >=10% of the last minute requests"
1. Note: the last minute!
1. Space of analyzer is constant and cannot depend on the number of requests
1. Result of requests write to hash-table

## 💘 Solution

There are two main parts:

### Buckets

We will answer on requests about not exactly the last 60 seconds, but the last 60-65 seconds (it is calculation error for availability to process billions of requests per second). Store 13 buckets for the last <= 65 seconds. Every 5 seconds erase the oldest bucket and create a new one. The processing of `get`/`set` requests affects all 13 buckets. When it is `get_top_k()` request, work with the oldest current bucket. 


### Estimation

Algorithm and all math are described in [this article](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.511.4581&rep=rep1&type=pdf). It is the so-called "Frequency Estimation Algorithm".

As a consequence of "4 Conclusions" for our task with `alpha = 0.1`:

| bucket_size | K for correct_Top_K = 1 / (0.1 - 0.9/bucket_size) |
| --- | --- |
| 10 | 100 |
| 18 | 20 |
| 27 | 15 | 
| 32 | 14 |
| 39 | 13 |
| 54 | 12 |
| 99 | 11 |

(generated by Python script)

   for i in range(10, 200):
      print(i, 1 / (0.1 - 0.9/i))
      
## 👪 Contributors

You are welcome! If you have any idea — you must write to us about it, implement it, and make a pull request! Or write an issue to discuss problems and ideas.

Current contributors list:

<a href="https://github.com/turing228" title="Github profile of Nikita Lisovetin">
    <img src="https://github.com/turing228.png" width="40" height="40">
    Nikita Lisovetin, student of ITMO University, Department of Computer Technologies. Developer.
</a>
 
 ## 📄 License

Map-Get-Fresh-Top-K is GNU GPL licensed, as found in the [LICENSE][l] file.

[l]: https://github.com/turing228/map-get-fresh-top-k/blob/master/LICENSE
